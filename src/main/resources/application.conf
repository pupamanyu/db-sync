#
# Copyright (C) 2018 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# This is a sample HOCON config.The config file can be in this format or Compact JSON
# There are tools to convert HOCON to Compact JSON
#
# Please refer: https://github.com/lightbend/config/blob/master/HOCON.md
#
# Copy the Customized JSON File or HOCON File to a GCS Bucket
# so that Spark workers can also access the file.

# Source DB Specific Config.
source {
    # Source JDBC URL String
    jdbcUrl = "jdbc:mysql://srcdbserver.example.com:3306/sourcedb?autoReconnect=true&useSSL=false&rewriteBatchedStatements=true&useCompression=true"
    # Source Table Name
    table = "srctable"
    # Source DB User
    user = "dbuser"
    # Source DB Password
    password = "xxxxxx"
    # List of Primary Column Names
    primaryColumns = ["id"]
    # Column Name to be used for Partitioning
    partitionColumn = "columnname"
    # Batch Fetch Size for JDBC Read
    batchFetchSize = 100000
    # JDBC Number of Partitions
    numPartitions = 40
    # extractType can be full or incremental or custom(requires lowerBound)
    extractType = "incremental"
    # Source Directory for the Avro, Parquet, or ORC files
    filesDir = "gs://<src bucket>/<some source dir>"
    # Source File Format to be used to Load the data
    fileFormat = "<avro>|<parquet>|<orc>"
    # Source Driver Name
    driver = "com.mysql.cj.jdbc.Driver"
    # For custom extractType(Required): Uncomment Lower Bound, will take precedence if supplied
    #lowerBound = <NUMERIC VALUE>
    # For custom extractType(Required): Uncomment Non-Inclusive Upper Bound, will take precedence if supplied
    #upperBound = <NUMERIC VALUE>
}

# Target DB Specific Config
target {
    # Target JDBC URL String
    jdbcUrl = "jdbc:mysql://targetdbserver.example.com:3306/targetdb?autoReconnect=true&useSSL=false&rewriteBatchedStatements=true&useCompression=true"
    # Target Table Name
    table = "dbtable"
    # Target DB User Name
    user = "dbuser"
    # Target DB Password
    password = "yyyyyy"
    # JDBC Batch Insert Size
    batchInsertSize = 100000
    # JDBC Number of Partitions
    numPartitions = 40
    # Target Directory for the Avro, Parquet, or ORC files
    filesDir = "gs://<src bucket>/<some target dir>"
    # Target File Format to be used to Save the data
    fileFormat = "<avro>|<parquet>|<orc>"
    # Target Driver Name
    driver = "com.mysql.cj.jdbc.Driver"
    # Set Source Dataframe Repartition to true. This may cause degradation. Use with caution
    sourceDFRepartition = "false"
    # Set Verification to True(May take Job to finish longer)
    verify = "false"
}
